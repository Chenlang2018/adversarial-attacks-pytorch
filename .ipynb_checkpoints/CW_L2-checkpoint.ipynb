{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import urllib.request as url_req\n",
    "import pickle\n",
    "from Model import get_model\n",
    "from utils import *\n",
    "import json\n",
    "from model_and_data import Data\n",
    "from FGSM import FGSM\n",
    "from BIM import BIM\n",
    "from visualize import visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(device)                  # loads a pretrained vgg11 model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarliniWagnerL2():\n",
    "    # https://github.com/rwightman/pytorch-nips2017-attack-example/blob/master/attacks/attack_carlini_wagner_l2.py\n",
    "    def __init__(self, orig_img, model, target, initial_constt, clip_min, clip_max, confidence_param, \n",
    "                 binary_search_steps, max_steps):\n",
    "        self.model = model\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "        self.confidence= confidence_param\n",
    "        self.bsearch_steps = binary_search_steps\n",
    "        self.num_classes = 100\n",
    "        self.target = target          # tensor\n",
    "        self.initial_constt = initial_constt\n",
    "        self.repeat = binary_search_steps >= 10\n",
    "        self.orig_img = orig_img\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "    def _compare(self, output, target):\n",
    "        if not isinstance(output, (float, int, np.int64)):\n",
    "            output = np.copy(output)\n",
    "            output[target] -= self.confidence\n",
    "            output = np.argmax(output)\n",
    "        \n",
    "        return output == target\n",
    "\n",
    "    \n",
    "    def _loss(self,output, target, dist, scale_constt):\n",
    "        # compute probability of the label class versus the maximum other\n",
    "        real = (target * output).sum(1)\n",
    "        other = ((1 - target) * output - target*10000).max(1)[0]   # target is one-hot encoded and \n",
    "                                                    # gives max{Z(x')<subs>i  where i!=t (t is target class)} \n",
    "            \n",
    "        loss1 = torch.clamp(other - real + self.confidence, min = 0.) \n",
    "        loss1 = torch.sum(scale_constt*loss1)\n",
    "        \n",
    "        loss2 = dist.sum()\n",
    "        loss = loss1+loss2\n",
    "        return loss\n",
    "    \n",
    "    def _optimize(self, optimizer, model, input_var, modifier_var, target_var, scale_const_var, input_orig=None):\n",
    "        input_adv = tanh_rescale(modifier_var+input_var, self.clip_min,self.clip_max)\n",
    "        \n",
    "        output = model(input_adv)\n",
    "        \n",
    "        if input_orig is None:\n",
    "            dist = l2_dist(input_adv, input_var,keepdim=False)\n",
    "        else:\n",
    "            dist = l2_dist(input_adv, input_orig, keepdim=False)\n",
    "            \n",
    "        loss = self._loss(output, target_var, dist, scale_const_var)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_np = loss.data[0]\n",
    "        dist_np = dist.data.cpu().numpy()\n",
    "        output_np = output.data.cpu().numpy()\n",
    "        input_adv_np = input_adv.data.permute(0, 2, 3, 1).cpu().numpy()  # back to BHWC for numpy consumption\n",
    "        return loss_np, dist_np, output_np, input_adv_np\n",
    "    \n",
    "    def run(self, model, inputs,target, batch_idx=0):\n",
    "        batch_size = inputs.size(0)\n",
    "        \n",
    "        # set the lower and upper bounds accordingly\n",
    "        lower_bound = np.zeros(batch_size)\n",
    "        scale_const = np.ones(batch_size) * self.initial_constt\n",
    "        upper_bound = np.ones(batch_size) * 1e10\n",
    "        \n",
    "        # python/numpy placeholders for the overall best l2, label score, and adversarial image\n",
    "        o_best_l2 = [1e10] * batch_size\n",
    "        o_best_score = [-1] * batch_size\n",
    "        o_best_attack = inputs.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "        \n",
    "        input_var = torch.tensor(torch_arctanh(inputs),requires_grad=False)\n",
    "        input_orig = tanh_rescale(input_var, self.clip_min, self.clip_max)\n",
    "        \n",
    "        target_onehot = torch.zeros(target.size() + (self.num_classes,))\n",
    "        target_onehot = target_onehot.cuda()\n",
    "        target_onehot.scatter_(1, target.unsqueeze(1), 1.)\n",
    "        target_var = torch.tensor(target_onehot, requires_grad=False)\n",
    "        \n",
    "        modifier = torch.zeros(input_var.size()).float()\n",
    "        \n",
    "        modifier = torch.normal(mean=modifier, std = 1e-3)\n",
    "        modifier = modifier.cuda()\n",
    "        modifier_var = torch.tensor(modifier, requires_grad=True)\n",
    "        \n",
    "        optimizer = optim.Adam([modifier_var], lr=5e-4)\n",
    "        \n",
    "        \n",
    "        for search_step  in range(self.bsearch_steps):\n",
    "            for i, x in enumerate(scale_const):\n",
    "                print(i, x)\n",
    "            best_l2 = [1e10] * batch_size\n",
    "            best_score = [-1] * batch_size\n",
    "            \n",
    "            if self.repeat and search_step == self.binary_search_steps - 1:\n",
    "                scale_const = upper_bound\n",
    "            \n",
    "            scale_const_tensor = torch.from_numpy(scale_const).float()\n",
    "            scale_const_tensor = scale_const_tensor.cuda()\n",
    "            scale_const_var = torch.tensor(scale_const_tensor,requires_grad=False)\n",
    "        \n",
    "            prev_loss = 1e6\n",
    "            for step in range(self.max_steps):\n",
    "                loss, dist, output, adv_img = self._optimize(\n",
    "                    optimizer,\n",
    "                    model,\n",
    "                    input_var,\n",
    "                    modifier_var,\n",
    "                    target_var,\n",
    "                    scale_const_var,\n",
    "                    input_orig)\n",
    "                if step % 100 == 0 or step == self.max_steps - 1:\n",
    "                    print('Step: {0:>4}, loss: {1:6.4f}, dist: {2:8.5f}, modifier mean: {3:.5e}'.format(\n",
    "                        step, loss, dist.mean(), modifier_var.data.mean()))\n",
    "                    \n",
    "                                 # update best result found\n",
    "                for i in range(batch_size):\n",
    "                    target_label = target[i]\n",
    "                    output_logits = output[i]\n",
    "                    output_label = np.argmax(output_logits)\n",
    "                    di = dist[i]\n",
    "                    if step % 100 == 0:\n",
    "                            print('{0:>2} dist: {1:.5f}, output: {2:>3}, {3:5.3}, target {4:>3}'.format(\n",
    "                                i, di, output_label, output_logits[output_label], target_label))   \n",
    "                \n",
    "                    if di < best_l2[i] and self._compare(output_logits, target_label):\n",
    "                \n",
    "                        best_l2[i] = di\n",
    "                        best_score[i] = output_label\n",
    "                    if di < o_best_l2[i] and self._compare(output_logits, target_label):\n",
    "                        o_best_l2[i] = di\n",
    "                        o_best_score[i] = output_label\n",
    "                        o_best_attack[i] = adv_img[i]\n",
    "        \n",
    "            batch_failure = 0\n",
    "            batch_success = 0\n",
    "            for i in range(batch_size):\n",
    "                if self._compare(best_score[i], target[i]) and best_score[i] != -1:\n",
    "                    # successful, do binary search and divide const by two\n",
    "                    upper_bound[i] = min(upper_bound[i], scale_const[i])\n",
    "                    if upper_bound[i] < 1e9:\n",
    "                        scale_const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
    "#                     if self.debug:\n",
    "#                         print('{0:>2} successful attack, lowering const to {1:.3f}'.format(\n",
    "#                             i, scale_const[i]))\n",
    "                else:\n",
    "                    # failure, multiply by 10 if no solution found\n",
    "                    # or do binary search with the known upper bound\n",
    "                    lower_bound[i] = max(lower_bound[i], scale_const[i])\n",
    "                    if upper_bound[i] < 1e9:\n",
    "                        scale_const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
    "                    else:\n",
    "                        scale_const[i] *= 10\n",
    "                if self._compare(o_best_score[i], target[i]) and o_best_score[i] != -1:\n",
    "                    batch_success += 1\n",
    "                else:\n",
    "                    batch_failure += 1\n",
    "\n",
    "            print('Num failures: {0:2d}, num successes: {1:2d}\\n'.format(batch_failure, batch_success))\n",
    "            sys.stdout.flush()\n",
    "            # end outer search loop\n",
    "\n",
    "        return o_best_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = os.listdir('imagenet_imgs/')\n",
    "batch_size = len(os.listdir('imagenet_imgs/'))\n",
    "for idx,img_name in enumerate(imgs):\n",
    "    print(idx)\n",
    "    img_path = os.path.join('imagenet_imgs/',img_name)\n",
    "    data = Data(model,device, None,None)\n",
    "    img_tsor = data.preprocess_data(Image.open(img_path))\n",
    "    #         imshow(img_tsor,'dgs')\n",
    "    img_tsor.unsqueeze_(0)\n",
    "    img_tsor = img_tsor.to(device)\n",
    "    img_tsor.requires_grad_(True)\n",
    "\n",
    "    label = img_name.split('_')[0]\n",
    "    label = torch.tensor([int(label)],requires_grad=False)\n",
    "    label = label.to(device)\n",
    "    #         print(label.shape)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    ############ Unperturbed Model ######################\n",
    "    unpert_output,unpert_pred, unpert_op_probs, unpert_pred_prob = getPredictionInfo(model,img_tsor)\n",
    "    \n",
    "    wagner = CarliniWagnerL2(img, model, targetLabel, 0.1, -1, 1, 0, 4,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results():\n",
    "    global model\n",
    "    model_misclassifns = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    misclassfns = 0\n",
    "    total = 0\n",
    "    wagner_att = None\n",
    "    eps = 0.1\n",
    "    eps_iter = 0.04\n",
    "    k=0\n",
    "    k_img = None\n",
    "    for i,data in enumerate(testset):\n",
    "        if i<10:\n",
    "#             print(i)\n",
    "            images_, labels_ = data\n",
    "            images, labels = images_, labels_\n",
    "\n",
    "            for img , label in zip(images, labels):\n",
    "                img = img.unsqueeze(0)      # to match dimensions when we input single image instead of mini-batch\n",
    "                img = img.to(device)\n",
    "                img.requires_grad_(True)\n",
    "                    \n",
    "                print(label)\n",
    "                label = label.unsqueeze(0)\n",
    "                \n",
    "                label = label.to(device)\n",
    "\n",
    "                unpert_predictedLabel, unpert_pred_prob = unperturbed_model(model,img,label)\n",
    "                targetLabel = torch.tensor([4],requires_grad=False).to(device)\n",
    "#                 lbfgs_att = LBFGS_Attack(model,criterion,img,label,unpert_predictedLabel,targetLabel,5,500,0,1,0.01,device)\n",
    "#                 adv_img = lbfgs_att.attack(img,targetLabel)\n",
    "\n",
    "#                 if i==3:\n",
    "#                     k+=2\n",
    "#                     if k==2:\n",
    "# #                         wagner = CarliniWagnerL2(img, model, targetLabel, 0.1, -1, 1, 0, 4,800)\n",
    "# #                         wagner_attack = wagner.run(model,img,targetLabel)\n",
    "# #                         wagner_att = wagner_attack\n",
    "# #                         k_img = img \n",
    "#                         pgd = PGDAttack(model,img,label,0.01,0.3,device)\n",
    "#                         advImg,losses = pgd.attack(30)\n",
    "#                         k_img = img\n",
    "                \n",
    "    print(total,misclassfns)\n",
    "    return img,label,adv_img,perturbation, pred_adv, adv_pred_prob\n",
    "#     return wagner_att,k_img\n",
    "#     print(total,success)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
